{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de Hiperparámetros\n",
    "\n",
    "*La terminología específica de ML puede diferir de otros campos.*\n",
    "\n",
    "- **Hiperparámetros**: Valores que configuran el entrenamiento del modelo, distintos de los parámetros aprendidos de los datos (ej. tasa de regularización en regresión logística, tasa de aprendizaje en redes neuronales convolucionales).\n",
    "\n",
    "- **Ajuste de Hiperparámetros**: Proceso de encontrar los mejores valores de hiperparámetros para un modelo dado, buscando optimizar una métrica de rendimiento (ej. precisión).\n",
    "\n",
    "Pasos en Azure ML:\n",
    "\n",
    "1. **Definir espacio de búsqueda**: Rango de valores posibles para cada hiperparámetro.\n",
    "2. **Configurar muestreo**: Método de selección de combinaciones de hiperparámetros para probar.\n",
    "3. **Seleccionar política de terminación temprana**: Detener experimentos con bajo rendimiento.\n",
    "4. **Ejecutar experimento**: Entrenar modelos con diferentes combinaciones de hiperparámetros, evaluar su rendimiento y seleccionar el mejor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de ML aprenden a predecir valores desconocidos (etiquetas) para datos nuevos basados en relaciones entre valores conocidos (etiquetas) y características presentes en los datos de entrenamiento. Dependiendo del algoritmo utilizado, puede ser necesario especificar hiperparámetros para configurar el entrenamiento del modelo. Estos son distintos de los parámetros aprendidos de los datos.\n",
    "\n",
    "El ajuste de hiperparámetros busca encontrar los mejores valores de estos parámetros para un modelo específico, optimizando una métrica de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Definiendo el espacio de búsqueda para ajuste de hiperparámetros\n",
    "\n",
    "El espacio de búsqueda es el conjunto de valores de hiperparámetros que se prueban durante el ajuste. Su definición depende del tipo de hiperparámetro:\n",
    "\n",
    "- **Discretos**: Requieren valores específicos de un conjunto limitado. Se definen mediante una lista de Python, un rango o valores separados por comas. También se pueden elegir de distribuciones discretas predefinidas.\n",
    "  - qnormal\n",
    "  - quniform\n",
    "  - qlognormal\n",
    "  - qloguniforme\n",
    "- **Continuos**: Pueden tomar cualquier valor dentro de un rango. Se definen mediante distribuciones continuas predefinidas.\n",
    "  - normal\n",
    "  - uniform\n",
    "  - lognormal\n",
    "  - loguniforme\n",
    "\n",
    "Para definir el espacio de búsqueda, se crea un diccionario con expresiones para cada hiperparámetro. \n",
    "  Por ejemplo, podemos especificar que el tamaño de lote sea 16, 32 o 64, y la tasa de aprendizaje pueda tomar cualquier valor de una distribución normal con media 10 y desviación estándar 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Configuración del muestreo\n",
    "\n",
    "Los valores específicos utilizados en una ejecución de ajuste de hiperparámetros dependen del tipo de muestreo utilizado.\n",
    "\n",
    "##### Muestreo de cuadrícula\n",
    "El muestreo de cuadrícula sólo puede emplearse cuando todos los hiperparámetros son discretos, y se utiliza para probar todas las combinaciones posibles de parámetros en el espacio de búsqueda.\n",
    "\n",
    "Por ejemplo, en el siguiente ejemplo de código, el muestreo de cuadrícula se utiliza para probar todas las combinaciones posibles del valor discreto de `batch_size` y `learning_rate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import GridParameterSampling, choice\n",
    "\n",
    "param_space = {\n",
    "                 '--batch_size': choice(16, 32, 64),\n",
    "                 '--learning_rate': choice(0.01, 0.1, 1.0)\n",
    "              }\n",
    "\n",
    "param_sampling = GridParameterSampling(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Muestreo aleatorio\n",
    "\n",
    "El muestreo aleatorio se usa para seleccionar aleatoriamente un valor para cada hiperparámetro, que puede ser una combinación de valores discretos y continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, choice, normal\n",
    "\n",
    "param_space = {\n",
    "                 '--batch_size': choice(16, 32, 64),\n",
    "                 '--learning_rate': normal(10, 3)\n",
    "              }\n",
    "\n",
    "param_sampling = RandomParameterSampling(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Muestreo bayesiano\n",
    "\n",
    "El muestreo bayesiano elige valores de hiperparámetros basados en el algoritmo de optimización bayesiana, que intenta seleccionar combinaciones de parámetros que darán como resultado un mejor rendimiento de la selección anterior.\n",
    "\n",
    "Solo puede usar el muestreo bayesiano con expresiones de parámetros choice, uniform y quniform, y no puede combinarlo con una directiva de terminación anticipada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import BayesianParameterSampling, choice, uniform\n",
    "\n",
    "param_space = {\n",
    "                 '--batch_size': choice(16, 32, 64),\n",
    "                 '--learning_rate': uniform(0.05, 0.1)\n",
    "              }\n",
    "\n",
    "param_sampling = BayesianParameterSampling(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Directivas de terminación anticipada para ajuste de hiperparámetros\n",
    "\n",
    "**Problema**: En espacios de búsqueda grandes, probar todas las combinaciones de hiperparámetros puede llevar mucho tiempo.\n",
    "\n",
    "**Solución**: Implementar una directiva de terminación anticipada para abandonar las ejecuciones con bajo rendimiento.\n",
    "\n",
    "Tipos de directivas:\n",
    "- **Política de bandidos**: Abandona una ejecución si su rendimiento es peor que el mejor hasta ahora por un margen especificado.\n",
    "- **Mediana de la política de detención**: Abandona las ejecuciones con un rendimiento peor que la media de todas las ejecuciones.\n",
    "- **Política de selección de truncamiento**: Cancela un porcentaje X de las ejecuciones con el peor rendimiento en cada intervalo de evaluación.\n",
    "\n",
    "Parámetros:\n",
    "- **Intervalo de evaluación**: Frecuencia con la que se evalúa la directiva.\n",
    "- **Retraso de evaluación**: Número mínimo de iteraciones antes de la primera evaluación.\n",
    "\n",
    "Beneficios:\n",
    "- Ahorro de tiempo y recursos computacionales.\n",
    "- Mayor eficiencia en la búsqueda de los mejores hiperparámetros.\n",
    "\n",
    "Aplicación:\n",
    "- Especialmente útil para el aprendizaje profundo, donde el entrenamiento es iterativo.\n",
    "- El script de entrenamiento puede informar la métrica de rendimiento después de cada época.\n",
    "- La directiva se puede aplicar después de un número específico de iteraciones.\n",
    "\n",
    "Ejemplo:\n",
    "- La directiva se aplica después de la iteración 5.\n",
    "- Se abandonan las ejecuciones con un rendimiento 0,2 o más peor que la mejor ejecución.\n",
    "\n",
    "Consideraciones:\n",
    "- Elegir la política adecuada para el caso de uso específico.\n",
    "- Ajustar los parámetros de la directiva para optimizar el rendimiento.\n",
    "\n",
    "\n",
    "Las directivas de terminación anticipada son una herramienta valiosa para acelerar el ajuste de hiperparámetros y mejorar la eficiencia del proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejecución de un experimento de ajuste de hiperparámetros\n",
    "\n",
    "En Azure ML, puedes ajustar los hiperparámetros ejecutando un experimento de hiperimpulsor.\n",
    "\n",
    "- **Creación de un script de entrenamiento para el ajuste de hiperparámetros**\n",
    "\n",
    "    Para llevar a cabo un experimento de hiperimpulsor, necesitamos crear un script de entrenamiento. Este proceso es similar al que seguiremos en cualquier otro experimento de entrenamiento, con la diferencia de que el script debe:\n",
    "\n",
    "    - Incluir un argumento para cada hiperparámetro que desees variar.\n",
    "    - Registrar la métrica de rendimiento objetivo. Esto permite que la ejecución del hiperimpulsor evalúe el rendimiento de las ejecuciones secundarias que inicia e identifique la que produce el modelo de mejor rendimiento.\n",
    "    \n",
    "    Por ejemplo, podrías tener un script que entrena un modelo de regresión logística. En este script, usarías un argumento `--regularization` para establecer el hiperparámetro de tasa de regularización y registrarías la métrica de precisión con el nombre `Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Obtener el hiparparametro de regularizacion\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Obtener el contexto de ejecucion\n",
    "run = Run.get_context()\n",
    "\n",
    "# Carga de datos\n",
    "data = run.input_datasets['training_data'].to_pandas_dataframe()\n",
    "\n",
    "# Separar los datos en caracteristicas y etiquetas\n",
    "X = data[['feature1','feature2','feature3','feature4']].values\n",
    "y = data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calcular y registrar la precision\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# guardar el modelo\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Configuración y ejecución de un experimento de hiperimpulsor**\n",
    "\n",
    "    Para preparar el experimento de hiperimpulsor, debemos usar un objeto `HyperDriveConfig` para configurar la ejecución del experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal\n",
    "\n",
    "# Asumiendo ws, script_config y param_sampling definidos previamente\n",
    "hyperdrive = HyperDriveConfig(run_config=script_config,\n",
    "                              hyperparameter_sampling=param_sampling,\n",
    "                              policy=None,\n",
    "                              primary_metric_name='Accuracy',\n",
    "                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                              max_total_runs=6,\n",
    "                              max_concurrent_runs=4)\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = 'hyperdrive_training')\n",
    "hyperdrive_run = experiment.submit(config=hyperdrive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Supervisión y revisión de las ejecuciones de hiperimpulsores**\n",
    "\n",
    "    Puede supervisar los experimentos de hiperimpulsores en Azure ML Studio o mediante el widget `RunDetails` de Jupyter Notebooks  .\n",
    "\n",
    "    El experimento iniciará una ejecución secundaria para cada combinación de hiperparámetros que se vaya a probar, y puede recuperar las métricas registradas que se ejecutan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child_run in run.get_children():\n",
    "    print(child_run.id, child_run.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede enumerar todas las ejecuciones en orden descendente de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child_run in hyperdrive_run.get_children_sorted_by_primary_metric():\n",
    "    print(child_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para recuperar la ejecución con mejor rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
